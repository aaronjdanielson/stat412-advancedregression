---
  title: "Stats 412 Problem Set 1"
  output: html_document
  author: Lucy Baden
  highlight: pygments
---


  
### The Sound of Gunfire, Off in the Distance
  Our first dataset this week comes from a study of the causes of civil wars.[^1] The data
can be read into from a csv posted online by using the following command.

```{r}
war <- read.csv("http://www.stat.cmu.edu/~cshalizi/uADA/15/hw/06/ch.csv", row.names = 1)
```

Every row of the data represents a combination of a country and of a five year interval — the
first row is Afghanistan, 1960, really meaning Afghanistan, 1960–1965. The 
variables are:
  
- The country name;
- The year;
- An indicator for whether a civil war began during that period: 1 indicates a 
civil war has begun, the code of NA means an on-going civil war, 0 means peace.
- Exports, really a measure of how dependent the country’s economy is on commodity exports;
- Secondary school enrollment rate for males, as a percentage;
- Annual growth rate in GDP;
- An index of the geographic concentration of the country’s population (which would be 1 if the entire population lives in one city, and 0 if it evenly spread across the territory);
- The number of months since the country’s last war or the end of World War II, whichever is more recent;
- The natural logarithm of the country’s population;
- An index of social “fractionalization”, which tries to measure how much the
country is divided along ethnic and/or religious lines;
- An index of ethnic dominance, which tries to measure how much one ethnic
group runs affairs in the country.

Some of these variables are NA for some countries.

### 1
**Estimate**: Fit a logistic regression model for the start of civil war on all other variables except country and year (yes, this makes some questionable assumptions about independent observations); include a quadratic term for exports. Report the coefficients and their standard errors, together with R’s p-values. Which ones are found to be significant at the 5% level?

```{r Ex1}
fit.1 <- glm(start ~ exports + schooling + growth + peace + concentration + lnpop + fractionalization + dominance + I(exports^2), data=war, family = binomial)
summary(fit.1)
```

  At the 5% level, the intercept, exports, schooling, growth, peace, concentration, lnpop, fractionalization, dominance, and the quadratic term for exports are all significant.
  
### 2
**Interpretation**: All parts of this question refer to the logistic regression model you just fit.

1. What is the model’s predicted probability for a civil war in India in the period beginning 1975? What probability would it predict for a country just like India in 1975, except that its male secondary school enrollment rate was 30 points higher? What probability would it predict for a country just like India in 1975, except that the ratio of commodity exports to GDP was 0.1 higher?

```{r Ex2.1a}
newdata1 = war[which(war$country == "India" & war$year == 1975),]
predict(fit.1, newdata = newdata1, type="response")
```

  The model's predicted probability for a civil war in India beginning in 1975 is 35.0%.


```{r Ex2.1b}
newdata2 = newdata1
newdata2$schooling = newdata2$schooling + 30
predict(fit.1, newdata = newdata2, type="response")
```

  The model's predicted probability for a country just like India in 1975, except with a male secondary enrollment rate that is 30 points higher, is 17.3%.
  
```{r Ex 2.1c}
newdata3 = newdata1
newdata3$exports = newdata3$exports + 0.1
predict(fit.1, newdata=newdata3, type="response")
```

  Finally, the model's predicted probability for a country just like India in 1975, except that the ratio of commodity exports to GDP was 0.1 higher, is 69.6%.


  2. What is the model’s predicted probability for a civil war in Nigeria in the period beginning 1965? What probability would it predict for a country just like Nigeria in 1965, except that its male secondary school enrollment rate was 30 points higher? What probability would it predict for a country just like Nigeria in 1965, except that the ratio of commodity exports to GDP was 0.1 higher?

```{r Ex2.2a}
newdata1 = war[which(war$country == "Nigeria" & war$year == 1965),]
predict(fit.1, newdata = newdata1, type="response")
```

  The model's predicted probability for a civil war in Nigeria in the period beginning 1965 is 17.1%.


```{r Ex2.2b}
newdata2 = newdata1
newdata2$schooling = newdata2$schooling + 30
predict(fit.1, newdata = newdata2, type="response")
```

  The model's predicted probability for a country just like Nigeria in 1965, except with a male secondary school enrollment rate that is 30 points higher, is 7.4%.
  
```{r Ex 2.2c}
newdata3 = newdata1
newdata3$exports = newdata3$exports + 0.1
predict(fit.1, newdata=newdata3, type="response")
```

  Finally, the model's predicted probability for a country just like Nigeria in 1965, except that the ratio of commodity exports to GDP was 0.1 higher, is 33.1%.

  
  3. In the parts above, you changed the same predictor variables by the same amounts. If you did your calculations properly, the changes in predicted probabilities are not equal. Explain why not. (The reasons may or may not be the same for the two variables.)
  
  The changes in the predicted probabilities are not equal even though the same predictor variables were changed by the same amounts because logistic regression uses a nonlinear logit link function. Thus even though the variables are changed linearly, the resulting response given by the logistic regression is nonlinear. The same change to the input variable produces different results because predicted probabilities change at different rates at different places on the link function.  
  


### 3
**Confusion**: Logistic regression predicts a probability of civil war for each country and period. Suppose we want to make a definite prediction of civil war or not, that is, to classify each data point. The probability of misclassification is minimized by predicting war if the probability is ≥ 0.5, and peace otherwise.

1. Build a 2 × 2 *confusion matrix* (a.k.a. “classification table” or “contigency table”) which counts: the number of outbreaks of civil war correctly predicted by the logistic regression; the number of civil wars not predicted by the model; the number of false predictions of civil wars; and the number of correctly predicted absences of civil wars. (Note that some entries in the table may be zero.)
```{r Ex3.1}
library(caret)
confusionMatrix(as.factor(round(fit.1$fitted)),as.factor(fit.1$y))$table
```

The logistic regression correctly predicts 3 outbreaks of civil war; the model does not predict 43 civil wars that occurred; the model gives 5 false predictions of civil wars; and the model correctly predicts 637 absences of civil wars.

2. What fraction of the logistic regression’s predictions are incorrect, i.e. what is the misclassification rate? (Note that this is if anything too kind to the model, since it’s looking at predictions to the same training data set).
```{r Ex3.2}
(43+5)/(637+43+5+3)
```

The misclassification rate is 6.98%.


3. Consider a foolish (?) pundit who always predicts “no war”. What fraction of the pundit’s predictions are correct on the whole data set? What fraction are correct on data points where the logistic regression model also makes a prediction?
```{r Ex3.3}
length(which(war$start == 0))/length(war$start)
length(which(na.omit(war)$start == 0))/nrow(na.omit(war))
```

84.5% of the pundit's predictions are correct on the whole dqata set, and 93.3% are correct on data points where the logistic regression model also makes a prediction.


### 4
  **Comparison**: Since this is a classification problem with only two classes, we can compare Logistic Regression right along side Discriminant Analysis. This will require some reading. (see Introduction to Statistical Learning pages 138-149)

1. Fit an Linear Discriminant Analysis (LDA) model using the same predictors that you used for your logistic regression model. What is the training misclassification rate?
```{r Ex4.1}
library(MASS)
fit.2 <- lda(start ~ exports + schooling + growth + peace + concentration + lnpop + fractionalization + dominance + I(exports^2), data=war)

preds <- predict(fit.2, war, method="predictive")
confusionMatrix(as.factor(preds$class),as.factor(war$start))$table

(42+5)/(637+42+5+4)
```

The training misclassification rate is 6.8%.

  2. Fit a Quadratic Discriminat Analysis (QDA) model using the very same predictors. What is the training misclassification rate? 
```{r Ex4.2}
fit.3 <- qda(start ~ exports + schooling + growth + peace + concentration + lnpop + fractionalization + dominance + I(exports^2), data=war)

preds.qda <- predict(fit.3, war, method="predictive")
confusionMatrix(as.factor(preds.qda$class),as.factor(war$start))$table

(0+572)/(70+0+572+46)
```

The training misclassification rate is 83.1%.

  3. How does the prediction accuracy of the three models compare? Why do you think this is?
  
  The logistic regression and LDA models have similar prediction accuracy, around 93% each. However, the logistic regression model and LDA model both almost always predict no civil war, and very rarely predict that a civil war will occur. On the other hand, the QDA model has very poor predictive accuracy, since it almost always predicts a civil war, and rarely predicts that no civil war will occur. 
  
  This probably occurs because civil wars are so rare in the dataset. There are only 78 examples of civil wars out of the 1288 data points. Additionally, a full 600 of the observations have NAs. Therefore, the models do not have many observations to train on, and there are particularly few observations of civil wars that the models can use to find meaningful patterns. 

  
  * * *
  
### 5
**ROC**: Construct an ROC curve for all three of your models. Plot the ROC curves of all three models on the same plot.
```{r Ex5.1}
require(ROCR)
fit <- vector("list",3)
fit[[1]] <- fit.1
fit[[2]] <- fit.2
fit[[3]] <- fit.3

pred <- perf <- vector("list",3)
pred[[1]] <- prediction(predict(fit.1, war, type="response"), war$start)

post.2 <- as.data.frame(predict(fit.2, war, method="predictive")$posterior)
post.2$pred2 <- apply(X=post.2, MARGIN=1, FUN=min)
pred[[2]] <- prediction(post.2$pred2, war$start)

post.3 <- as.data.frame(predict(fit.3, war, method="predictive")$posterior)
post.3$pred3 <- apply(X=post.3, MARGIN=1, FUN=max)
pred[[3]] <- prediction(post.3$pred3, war$start)


for (i in 1:3) perf[[i]] <- performance(pred[[i]], measure="tpr", x.measure="fpr")
for (i in 1:3) print(performance(pred[[i]], measure="auc")@y.values[[1]]) ## Area under curve
col <- c("#FF4E37FF", "#00B500FF", "#008DFFFF")
plot(perf[[1]], lwd=2, col=col[1])
plot(perf[[2]], add=TRUE, col=col[2], lwd=2)
plot(perf[[3]], add=TRUE, col=col[3], lwd=2)
legend("topleft", col=col, legend=c("LR", "LDA", "QDA"), lwd=2)
```

[^1]: Based on an exercise of Cosmo Shalizi's that uses data from Collier, Paul and Anke Hoeffler (2004). *Greed and Grievance in Civil War.* Oxford Economic Papers, 56: 563–595. URL: http://economics.ouls.ox.ac.uk/12055/1/2002-01text.pdf.


### 6

Fit a logistic regression using `y` as the response with `x1` and `x2` as indepedent variables. Does anything strange happen? Explain. 

```{r}
y<- c(0,0,0,0,1,1,1,1)
x1<-c(1,2,3,3,5,6,10,11)
x2<-c(3,2,-1,-1,2,4,1,0)
```


```{r Ex6.1}
fit.4 <- glm(y ~ x1 + x2, family=binomial)
```

Yes, we get a warning saying that fitted probabilities numerically 0 or 1 occurred. This happens because the data is perfectly separated, so the model can perfectly predict the value of y.


